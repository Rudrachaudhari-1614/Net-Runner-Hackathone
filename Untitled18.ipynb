{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tIqmkjzgnG9",
        "outputId": "2e7da9d2-5e28-445b-d95f-4b6312830c06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.2.2)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.3)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.10.0)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.62.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=146b34e975065d125bd9c84bc11ef436ce01d8b93c354a51104984570d19ce12\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, python-dotenv, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "Successfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.110.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.17.1 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.4.2 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.36.3 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.21 (from langchain)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.26 (from langchain)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.12-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.9 langchain-community-0.0.24 langchain-core-0.1.28 langsmith-0.1.12 marshmallow-3.21.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-4.0.2-py3-none-any.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.0/284.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-4.0.2\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install chromadb\n",
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikKcu66dg8y4"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "import sys\n",
        "\n",
        "# Load the pdf file and split it into smaller chunks\n",
        "loader = PyPDFLoader(\"TanishaPatel_resume.pdf\")\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# Load the text file\n",
        "loader = TextLoader(\"Tanisha Patel .txt\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Split the documents into smaller chunks\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "embeddings = HuggingFaceEmbeddings()\n",
        "db = Chroma.from_documents(texts, embeddings)\n",
        "retriever = db.as_retriever(search_kwargs={'k': 2})\n",
        "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm = HuggingFaceHub(huggingfacehub_api_token='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',\n",
        "                     repo_id=repo_id, model_kwargs={\"temperature\":0.2, \"max_new_tokens\":200})\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever,return_source_documents=True)\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "# # Define multiple preset queries\n",
        "# preset_queries = [\n",
        "#     \"Provide Educational Details\",\n",
        "#     \"Provide Work Experience\",\n",
        "#     \"Provide all the skills\",\n",
        "#     \"Extract all the Job Titles from work experience with timeline\"\n",
        "# ]\n",
        "\n",
        "# for query in preset_queries:\n",
        "#     result = qa_chain({'question': query, 'chat_history': chat_history})\n",
        "#     print('Question:', query)\n",
        "\n",
        "#     # Extracting the relevant part of the answer\n",
        "#     answer = result['answer']\n",
        "#     helpful_index = answer.find(\"Helpful Answer:\")\n",
        "#     if helpful_index != -1:\n",
        "#         answer = answer[helpful_index+len(\"Helpful Answer:\"):]\n",
        "\n",
        "#     print('Answer:', answer.strip() + '\\n')\n",
        "#     chat_history.append((query, answer.strip()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZdsqsg0hMuX"
      },
      "outputs": [],
      "source": [
        "# Define the filename for storing the information\n",
        "filename = \"stored_information.txt\"\n",
        "\n",
        "# Define a function to save the information to a text file\n",
        "def save_information(data):\n",
        "    with open(filename, 'w') as file:\n",
        "        for query, answer in data.items():\n",
        "            file.write(f\"Question: {query}\\n\")\n",
        "            file.write(f\"Answer: {answer}\\n\\n\")\n",
        "\n",
        "# Initialize an empty dictionary to store the information\n",
        "stored_information = {}\n",
        "\n",
        "# Define multiple preset queries\n",
        "preset_queries = [\n",
        "    \"Provide Educational Details\",\n",
        "    \"Provide Work Experience\",\n",
        "    \"Provide all the skills\",\n",
        "    \"Extract all the Job Titles from work experience with timeline\",\n",
        "    \"List skills\"\n",
        "]\n",
        "\n",
        "# Iterate over preset queries and store the results\n",
        "for query in preset_queries:\n",
        "    result = qa_chain({'question': query, 'chat_history': chat_history})\n",
        "    answer = result['answer']\n",
        "    helpful_index = answer.find(\"Helpful Answer:\")\n",
        "    if helpful_index != -1:\n",
        "        answer = answer[helpful_index+len(\"Helpful Answer:\"):]\n",
        "\n",
        "    stored_information[query] = answer.strip()\n",
        "\n",
        "    # Print and store the information\n",
        "    print('Question:', query)\n",
        "    print('Answer:', stored_information[query] + '\\n')\n",
        "\n",
        "# Save the stored information to a text file\n",
        "save_information(stored_information)\n",
        "\n",
        "print(\"Information has been saved to\", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "simqAPGAlQLs"
      },
      "outputs": [],
      "source": [
        "!pip install skillNer\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "QFZDGlABg92A",
        "outputId": "9c81968e-cd7e-4074-c8e7-b1d6d5a8e1a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading full_matcher ...\n",
            "loading abv_matcher ...\n",
            "loading full_uni_matcher ...\n",
            "loading low_form_matcher ...\n",
            "loading token_matcher ...\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'TextLoader' object has no attribute 'replace'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8182cc1a4c4b>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mjob_description\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"extracted_text (2).txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskill_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skillNer/skill_extractor_class.py\u001b[0m in \u001b[0;36mannotate\u001b[0;34m(self, text, tresh)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# create text object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtext_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# get matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         skills_full, text_obj = self.skill_getters.get_full_match_skills(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skillNer/text_class.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, nlp)\u001b[0m\n\u001b[1;32m    146\u001b[0m         )\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformed_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;31m# abv version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabv_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skillNer/cleaner.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcleaning_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_cleaning_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcleaning_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_cleaning_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m                     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_cleaning_functions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcleaning_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skillNer/cleaner.py\u001b[0m in \u001b[0;36mremove_punctuation\u001b[0;34m(text, list_punctuations)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_punctuations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# use .strip() to remove extra space in the begining/end of the text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TextLoader' object has no attribute 'replace'"
          ]
        }
      ],
      "source": [
        "!pip install skillNer\n",
        "!python -m spacy download en_core_web_lg\n",
        "\n",
        "import spacy\n",
        "import en_core_web_lg\n",
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "# import skill extractor\n",
        "from skillNer.skill_extractor_class import SkillExtractor\n",
        "from skillNer.general_params import SKILL_DB\n",
        "\n",
        "\n",
        "# init params of skill extractor\n",
        "nlp = en_core_web_lg.load()\n",
        "# init skill extractor\n",
        "skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)\n",
        "\n",
        "# extract skills from job_description\n",
        "# loader = TextLoader(\"Tanisha Patel .txt\")\n",
        "job_description = TextLoader(\"Tanish Patel.txt\") \"\"\"\n",
        " Rushabh Shah\n",
        "Raleigh, NC  | rsshah7@ncsu.edu  | (919) 539 -7895 | www.linkedin.com/in/rushabh -shah -b66b66211\n",
        "Skills\n",
        "\n",
        "Languages  and Database : Python  ,HTML , CSS, JavaScript , C, MySQL\n",
        "AI and Machine Learning : Scikit Learn, Tensorflow, NLTK, OpenCV\n",
        "Certifications: Data Visualisation with Python ( IBM), Machine Learning with Python ( IBM), Python Bootcamp ( NPTEL ),\n",
        "AWS Cloud Practitioner ( Amazon  Web Services ) , Interactivity with JavaScript( University of Michigan ), Generative AI\n",
        "Fundamentals (Google  Cloud )\n",
        "Work Experience\n",
        "\n",
        "Machine Learning  Developer  Intern , Agilo Research Pvt. Ltd.  (STEMpedia) , India ,   Jan ’23 – May ‘23\n",
        "• Played a key role in establishing and designing the AI Robotics Lab of STEMpedia, along with developing the Natural Language\n",
        "Processing, Generalized Classification feature for the Pictoblox Educational Software.\n",
        "• Developed and executed Python -based Machine Learning algorithms proficiently, prioritizing accessibility and\n",
        "comprehensibility for students.\n",
        "Cyber Security Management Intern , Alcumus ISO-QAR , India,      June ’22 - July ‘22\n",
        "• Demonstrated proficiency in interpreting ISO -27001 and subsequently developing an analogous framework as per the\n",
        "company requirement.\n",
        "• Proposed  a comprehensive Quantitative Risk Assessment framework to identify , assess and mitigate security vulnerabilities\n",
        "within business processes.\n",
        "Front End Developer , Code Karo Yaaro , India        April ’21 - June ‘21\n",
        "• Crafted and formulated webpages for an NGO's website in alignment with specified requisites in a team. The NGO's\n",
        "requirement was centred around creating a website that would help advancing women's empowerment and providing\n",
        "complimentary education to young children in rural areas.\n",
        "• Utilized HTML, CSS, and JavaScript languages to establish the website  including different webpages for services and funding\n",
        "options for the NGO . Collaborated with the developers to ensure the needs of the organisation are satisfied.\n",
        "Projects\n",
        "\n",
        "Education\n",
        "\n",
        "Masters in Computer Science           May  ‘25\n",
        "North Carolina State University , Raleigh\n",
        "Coursewor k: Automated Learning And Data Analysis, Design Analysis and Algorithm, Cloud Architecture\n",
        "B. Tech in Computer Engineering           May 2023\n",
        "Pandit Deendayal Energy University , Gandhinagar, India        CGPA: 9.63\n",
        "\"\"\"\n",
        "\n",
        "annotations = skill_extractor.annotate(job_description)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy7N5rpWiSoH"
      },
      "outputs": [],
      "source": [
        "skill_extractor.describe(annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3XVXO_tt0TP"
      },
      "outputs": [],
      "source": [
        "print(annotations)\n",
        "data = annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jW8IB-pjt3gs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "# def load_skills_from_csv(file_path):\n",
        "#     # Load the skills from CSV\n",
        "#     return pd.read_csv(file_path)\n",
        "\n",
        "def check_similarity(skill_resume, all_skills, threshold=100):\n",
        "    # Check similarity using fuzzywuzzy library\n",
        "    similarities = [fuzz.token_set_ratio(skill_resume, skill_data) for skill_data in all_skills]\n",
        "    max_similarity = max(similarities)\n",
        "\n",
        "    if max_similarity >= threshold:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "# Load the skills from the resume and dataset CSV files\n",
        "resume_skills = doc_node_values  # Replace with your actual file path\n",
        "all_skills = pd.Series(['programming',\n",
        " 'python',\n",
        " 'java',\n",
        " 'c++',\n",
        " 'reactjs',\n",
        " 'web development',\n",
        " 'html',\n",
        " 'cs',\n",
        " 'javascript',\n",
        " 'reactjs',\n",
        " 'flask',\n",
        " 'flutter',\n",
        " 'database management: sql',\n",
        " 'mongodb',\n",
        " 'cloud computing: aws (ec2',\n",
        " 's3)',\n",
        " 'project management',\n",
        " 'communication',\n",
        " 'problem solving',\n",
        " 'time management',\n",
        " 'data analysis: excel',\n",
        " 'panda',\n",
        " 'numpy',\n",
        " 'ux/ui design',\n",
        " 'network security',\n",
        " 'statistical modeling',\n",
        " 'adaptability',\n",
        " 'collaboration',\n",
        " 'leadership',\n",
        " 'emotional intelligence',\n",
        " 'healthcare informatics',\n",
        " 'e-commerce strategies',\n",
        " 'renewable energy technologies',\n",
        " 'certifications: csm',\n",
        " 'aws certified solutions architect',\n",
        " 'pmp',\n",
        " 'languages: english',\n",
        " 'spanish',\n",
        " 'french (basic)',\n",
        " 'software development',\n",
        " 'responsive web design',\n",
        " 'data storage and retrieval',\n",
        " 'cloud solutions',\n",
        " 'cross-functional team leadership',\n",
        " 'critical thinking',\n",
        " 'ux/ui prototyping',\n",
        " 'network protection',\n",
        " 'data interpretation',\n",
        " 'agile methodologies',\n",
        " 'digital marketing',\n",
        " 'customer engagement',\n",
        " 'environmental impact assessment',\n",
        " 'continuous language learning',\n",
        " 'multicultural communication',\n",
        " 'team collaboration',\n",
        " 'project delivery',\n",
        " 'interpersonal skills',\n",
        " 'electronic health records (ehr)',\n",
        " 'online sales optimization',\n",
        " 'sustainable energy',\n",
        " 'scrum methodology',\n",
        " 'system design',\n",
        " 'security measures',\n",
        " 'decision-making skills',\n",
        " 'data standards',\n",
        " 'interoperability',\n",
        " 'environmental awareness',\n",
        " 'language proficiency',\n",
        " 'version control (e.g.',\n",
        " 'git)',\n",
        " 'front-end frameworks (e.g.',\n",
        " 'react',\n",
        " 'angular)',\n",
        " 'back-end frameworks (e.g.',\n",
        " 'django',\n",
        " 'flask)',\n",
        " 'api design and integration',\n",
        " 'mobile app development',\n",
        " 'devops practices',\n",
        " 'containerization (e.g.',\n",
        " 'docker)',\n",
        " 'continuous integration/continuous deployment (ci/cd)',\n",
        " 'machine learning concepts',\n",
        " 'natural language processing (nlp)',\n",
        " 'cybersecurity measures',\n",
        " 'blockchain technology',\n",
        " 'big data technologies (e.g.',\n",
        " 'hadoop',\n",
        " 'spark)',\n",
        " 'virtualization technologies',\n",
        " 'a/b testing',\n",
        " 'user research',\n",
        " 'wireframing',\n",
        " 'cloud security',\n",
        " 'risk assessment',\n",
        " 'marketing analytics',\n",
        " 'sales forecasting',\n",
        " 'customer relationship management (crm)',\n",
        " 'supply chain management',\n",
        " 'quality assurance and testing',\n",
        " 'agile project tracking tools (e.g.',\n",
        " 'jira)',\n",
        " 'network protocols (e.g.',\n",
        " 'tcp/ip)',\n",
        " 'serverless architecture',\n",
        " 'microservices architecture',\n",
        " 'api documentation',\n",
        " 'technical writing',\n",
        " 'negotiation skills',\n",
        " 'conflict resolution',\n",
        " 'decision-making under uncertainty',\n",
        " 'strategic planning',\n",
        " 'financial literacy',\n",
        " 'budget management',\n",
        " 'presentation skills',\n",
        " 'public speaking',\n",
        " 'creative thinking',\n",
        " 'critical evaluation of information',\n",
        " 'research and information synthesis',\n",
        " 'project coordination',\n",
        " 'team building',\n",
        " 'employee training and development',\n",
        " 'time estimation',\n",
        " 'customer service',\n",
        " 'sales skills',\n",
        " 'market research',\n",
        " 'vendor management',\n",
        " 'public relations',\n",
        " 'emotional resilience',\n",
        " 'stress management',\n",
        " 'adaptation to change',\n",
        " 'cross-cultural communication',\n",
        " 'networking',\n",
        " 'conflict management',\n",
        " 'leadership development',\n",
        " 'decision-making under pressure',\n",
        " 'problem-solving in ambiguous situations',\n",
        " 'stakeholder engagement',\n",
        " 'entrepreneurial mindset',\n",
        " 'business development',\n",
        " 'data privacy compliance',\n",
        " 'regulatory compliance',\n",
        " 'legal knowledge',\n",
        " 'contract negotiation',\n",
        " 'supply chain optimization',\n",
        " 'change management',\n",
        " 'employee engagement',\n",
        " 'diversity and inclusion',\n",
        " 'crisis management',\n",
        " 'sustainability practices',\n",
        " 'corporate social responsibility',\n",
        " 'media relations',\n",
        " 'market trend analysis',\n",
        " 'foreign language proficiency',\n",
        " 'cultural sensitivity',\n",
        " 'conflict of interest resolution',\n",
        " 'client relationship management',\n",
        " 'ethical decision-making',\n",
        " 'remote collaboration',\n",
        " 'time zone management',\n",
        " 'vendor negotiation',\n",
        " 'financial analysis',\n",
        " 'risk management',\n",
        " 'business process optimization',\n",
        " 'mentoring and coaching',\n",
        " 'workplace safety',\n",
        " 'data governance',\n",
        " 'influencing skills',\n",
        " 'public policy analysis',\n",
        " 'community engagement',\n",
        " 'advocacy',\n",
        " 'grant writing',\n",
        " 'event planning and coordination',\n",
        " 'volunteer management',\n",
        " 'fundraising',\n",
        " 'crisis communication',\n",
        " 'interpersonal conflict resolution',\n",
        " 'empathy',\n",
        " 'cross-functional collaboration',\n",
        " 'client retention',\n",
        " 'business analytics',\n",
        " 'lean six sigma',\n",
        " 'conflict of interest resolution',\n",
        " 'social media management',\n",
        " 'emotional intelligence',\n",
        " 'time blocking',\n",
        " 'task delegation',\n",
        " 'organizational skills',\n",
        " 'knowledge management',\n",
        " 'self-motivation',\n",
        " 'customer feedback analysis',\n",
        " 'it service management',\n",
        " 'remote team leadership',\n",
        " 'knowledge transfer',\n",
        " 'learning agility',\n",
        " 'global business awareness',\n",
        " 'business continuity planning',\n",
        " 'influencer marketing',\n",
        " 'cultural competence',\n",
        " 'design thinking',\n",
        " 'storytelling',\n",
        " 'vendor relationship management',\n",
        " 'brand development',\n",
        " 'it governance',\n",
        " 'competitive analysis',\n",
        " 'ethical leadership',\n",
        " 'social responsibility planning',\n",
        " 'remote collaboration tools',\n",
        " 'designing training programs',\n",
        " 'information security compliance',\n",
        " 'workplace wellness programs',\n",
        " 'customer success management',\n",
        " 'regulatory reporting',\n",
        " 'team conflict resolution',\n",
        " 'presentation design',\n",
        " 'behavioral economics',\n",
        " 'continuous learning culture',\n",
        " 'multitasking',\n",
        " 'crowdsourcing',\n",
        " 'sustainability reporting',\n",
        " 'organizational change',\n",
        " 'corporate training',\n",
        " 'influencing without authority',\n",
        " 'grant management',\n",
        " 'workplace inclusivity',\n",
        " 'blockchain governance',\n",
        " 'user documentation',\n",
        " 'it risk management',\n",
        " 'microsoft office suite: word',\n",
        " 'excel',\n",
        " 'powerpoint',\n",
        " 'outlook',\n",
        " 'google workspace: docs',\n",
        " 'sheet',\n",
        " 'slide',\n",
        " 'gmail',\n",
        " 'project management tools: trello',\n",
        " 'asana',\n",
        " 'version control systems: git',\n",
        " 'github',\n",
        " 'customer relationship management (crm) software',\n",
        " 'collaboration and communication tools: slack',\n",
        " 'microsoft teams',\n",
        " 'data visualization tools: tableau',\n",
        " 'power bi',\n",
        " 'code editors: visual studio code',\n",
        " 'sublime text',\n",
        " 'integrated development environments (ides)',\n",
        " 'content management systems: wordpress',\n",
        " 'drupal',\n",
        " 'graphic design software: adobe creative cloud',\n",
        " 'video editing tools: adobe premiere',\n",
        " 'final cut pro',\n",
        " 'database management systems: mysql',\n",
        " 'postgresql',\n",
        " 'cloud platforms: aws',\n",
        " 'azure',\n",
        " 'google cloud',\n",
        " 'customer support software: zendesk',\n",
        " 'freshdesk',\n",
        " 'social media management tools: hootsuite',\n",
        " 'buffer',\n",
        " 'marketing automation platforms: hubspot',\n",
        " 'marketo',\n",
        " 'continuous integration/continuous deployment (ci/cd) tools',\n",
        " 'virtualization tools: vmware',\n",
        " 'virtualbox',\n",
        " 'network monitoring tools: wireshark',\n",
        " 'nagios',\n",
        " 'cybersecurity tools: wireshark',\n",
        " 'metasploit',\n",
        " 'e-commerce platforms: shopify',\n",
        " 'magento',\n",
        " 'learning management systems (lms)',\n",
        " 'data warehousing tools: snowflake',\n",
        " 'amazon redshift',\n",
        " 'password management tools: lastpass',\n",
        " '1password',\n",
        " 'machine learning algorithms',\n",
        " 'deep learning frameworks: tensorflow',\n",
        " 'pytorch',\n",
        " 'natural language processing (nlp)',\n",
        " 'computer vision',\n",
        " 'reinforcement learning',\n",
        " 'neural network design',\n",
        " 'ai model deployment',\n",
        " 'transfer learning',\n",
        " 'data preprocessing for ml',\n",
        " 'feature engineering',\n",
        " 'model evaluation and optimization',\n",
        " 'hyperparameter tuning',\n",
        " 'explainable ai',\n",
        " 'time series analysis',\n",
        " 'anomaly detection',\n",
        " 'generative adversarial networks (gans)',\n",
        " 'automl (automated machine learning)',\n",
        " 'ai ethics and bias mitigation',\n",
        " 'chatbot development',\n",
        " 'speech recognition',\n",
        " 'image classification',\n",
        " 'predictive modeling',\n",
        " 'recommendation systems',\n",
        " 'clustering algorithms',\n",
        " 'time series forecasting',\n",
        " 'structural design in civil engineering',\n",
        " 'project planning and management in civil engineering',\n",
        " 'geotechnical engineering in civil engineering',\n",
        " 'environmental impact assessment in civil engineering',\n",
        " 'cad/cam design in mechanical engineering',\n",
        " 'thermodynamics in mechanical engineering',\n",
        " 'finite element analysis (fea) in mechanical engineering',\n",
        " 'robotics in mechanical engineering',\n",
        " 'circuit design in electrical engineering',\n",
        " 'power systems in electrical engineering',\n",
        " 'control systems in electrical engineering',\n",
        " 'renewable energy systems in electrical engineering',\n",
        " 'reactjs',\n",
        " 'flask',\n",
        " 'flutter',\n",
        " 'process optimization in chemical engineering',\n",
        " 'material science in chemical engineering',\n",
        " 'aerodynamics in aerospace engineering',\n",
        " 'avionics in aerospace engineering',\n",
        " 'medical imaging in biomedical engineering',\n",
        " 'biomaterials in biomedical engineering',\n",
        " 'clinical diagnosis for doctors',\n",
        " 'patient care and communication for doctors',\n",
        " 'medical research for doctors',\n",
        " 'patient advocacy in nursing',\n",
        " 'emergency response in nursing',\n",
        " 'medication management for pharmacists',\n",
        " 'regulatory compliance for pharmacists',\n",
        " 'animal care in veterinary medicine',\n",
        " 'surgical procedures in veterinary medicine',\n",
        " 'architectural design',\n",
        " 'painting and drawing in fine arts',\n",
        " 'stage management in performing arts',\n",
        " 'adobe creative suite in graphic design',\n",
        " 'textile selection in fashion design',\n",
        " 'space planning in interior design',\n",
        " 'sustainability practices in environmental science',\n",
        " 'pollution control in environmental science',\n",
        " 'financial analysis',\n",
        " 'risk management',\n",
        " 'budgeting and forecasting',\n",
        " 'investment analysis',\n",
        " 'financial modeling',\n",
        " 'auditing',\n",
        " 'tax planning',\n",
        " 'regulatory compliance',\n",
        " 'corporate finance',\n",
        " 'financial reporting',\n",
        " 'data analysis in finance',\n",
        " 'business valuation',\n",
        " 'asset management',\n",
        " 'portfolio management',\n",
        " 'financial planning',\n",
        " 'econometrics',\n",
        " 'derivatives trading',\n",
        " 'merger and acquisition analysis',\n",
        " 'fraud detection',\n",
        " 'credit analysis',\n",
        " 'treasury management',\n",
        " 'cost accounting',\n",
        " 'international finance',\n",
        " 'financial software proficiency (e.g.',\n",
        " 'sap',\n",
        " 'quickbooks)',\n",
        " 'securities and exchange compliance',\n",
        " 'private equity analysis',\n",
        " 'corporate governance',\n",
        " 'fixed income analysis',\n",
        " 'financial risk assessment',\n",
        " 'cryptocurrency knowledge',\n",
        " 'legal research and writing (legal profession)',\n",
        " 'case management (legal profession)',\n",
        " 'financial analysis (finance)',\n",
        " 'risk assessment (insurance)',\n",
        " 'quality control (manufacturing)',\n",
        " '3d modeling (animation and design)',\n",
        " 'video editing (media and entertainment)',\n",
        " 'emergency medicine (emergency medical services)',\n",
        " 'clinical psychology (psychology)',\n",
        " 'social work (social services)',\n",
        " 'curriculum development (education)',\n",
        " 'classroom management (education)',\n",
        " 'event planning (event management)',\n",
        " 'culinary arts (culinary)',\n",
        " 'sales forecasting (retail)',\n",
        " 'employee relations',\n",
        " 'recruitment and staffing',\n",
        " 'hr compliance',\n",
        " 'performance management',\n",
        " 'training and development',\n",
        " 'compensation and benefits administration',\n",
        " 'hris (human resources information systems)',\n",
        " 'employee engagement',\n",
        " 'agricultural labor laws',\n",
        " 'farmworker recruitment',\n",
        " 'workforce management',\n",
        " 'agricultural safety practices',\n",
        " 'crop harvesting coordination',\n",
        " 'collective bargaining',\n",
        " 'conflict resolution',\n",
        " 'labor law compliance',\n",
        " 'negotiation skills',\n",
        " 'grievance handling',\n",
        " 'supply chain management',\n",
        " 'inventory control',\n",
        " 'logistics planning',\n",
        " 'transportation management',\n",
        " 'procurement',\n",
        " 'vendor management',\n",
        " 'process optimization',\n",
        " 'systems analysis',\n",
        " 'warehouse layout planning',\n",
        " 'lean manufacturing',\n",
        " 'six sigma',\n",
        " 'data analysis',\n",
        " 'report generation',\n",
        " 'performance metrics tracking',\n",
        " 'freight analysis',\n",
        " 'logistics software proficiency',\n",
        " 'project planning',\n",
        " 'risk management',\n",
        " 'budgeting',\n",
        " 'stakeholder communication',\n",
        " 'agile methodologies',\n",
        " 'gantt chart creation',\n",
        " 'management analysts:',\n",
        " 'process improvement',\n",
        " 'data analysis',\n",
        " 'strategic planning',\n",
        " 'business performance metrics',\n",
        " 'market research',\n",
        " 'meeting',\n",
        " 'convention',\n",
        " 'and event planners:',\n",
        " 'event coordination',\n",
        " 'budget management',\n",
        " 'vendor negotiation',\n",
        " 'contract management',\n",
        " 'creative problem solving',\n",
        " 'fundraisers:',\n",
        " 'donor relations',\n",
        " 'grant writing',\n",
        " 'fundraising event planning',\n",
        " 'campaign management',\n",
        " 'relationship building',\n",
        " 'compensation',\n",
        " 'benefit',\n",
        " 'and job analysis specialists:',\n",
        " 'compensation analysis',\n",
        " 'benefits administration',\n",
        " 'job evaluation',\n",
        " 'market salary surveys',\n",
        " 'hr compliance',\n",
        " 'training and development specialists:',\n",
        " 'training program design',\n",
        " 'learning management systems (lms)',\n",
        " 'employee development',\n",
        " 'training evaluation',\n",
        " 'instructional design',\n",
        " 'market research analysts and marketing specialists:',\n",
        " 'data analysis',\n",
        " 'market segmentation',\n",
        " 'consumer behavior analysis',\n",
        " 'competitor analysis',\n",
        " 'survey design',\n",
        " 'search marketing strategists:',\n",
        " 'seo (search engine optimization)',\n",
        " 'sem (search engine marketing)',\n",
        " 'keyword research',\n",
        " 'google analytics',\n",
        " 'content strategy',\n",
        " 'business operations specialists',\n",
        " 'all other:',\n",
        " 'process optimization',\n",
        " 'data analysis',\n",
        " 'change management',\n",
        " 'quality assurance',\n",
        " 'risk assessment',\n",
        " 'business continuity planners:',\n",
        " 'risk assessment',\n",
        " 'crisis management',\n",
        " 'disaster recovery planning',\n",
        " 'business impact analysis',\n",
        " 'emergency preparedness',\n",
        " 'sustainability specialists:',\n",
        " 'environmental impact assessment',\n",
        " 'sustainable practices',\n",
        " 'renewable energy strategies',\n",
        " 'carbon footprint analysis',\n",
        " 'eco-friendly initiatives',\n",
        " 'online merchants:',\n",
        " 'e-commerce platforms',\n",
        " 'online marketing',\n",
        " 'customer relationship management (crm)',\n",
        " 'inventory management',\n",
        " 'payment gateway integration',\n",
        " 'security management specialists:',\n",
        " 'security risk assessment',\n",
        " 'access control',\n",
        " 'emergency response planning',\n",
        " 'security systems management',\n",
        " 'threat analysis',\n",
        " 'accountants and auditors:',\n",
        " 'financial accounting',\n",
        " 'auditing standards',\n",
        " 'tax preparation',\n",
        " 'budget analysis',\n",
        " 'forensic accounting',\n",
        " 'appraisers of personal and business property:',\n",
        " 'valuation methods',\n",
        " 'appraisal standards',\n",
        " 'market analysis',\n",
        " 'asset valuation',\n",
        " 'reporting',\n",
        " 'appraisers and assessors of real estate:',\n",
        " 'real estate valuation',\n",
        " 'property assessment',\n",
        " 'market trends analysis',\n",
        " 'regulatory compliance',\n",
        " 'property inspection',\n",
        " 'budget analysts:',\n",
        " 'budget planning',\n",
        " 'financial forecasting',\n",
        " 'variance analysis',\n",
        " 'cost estimation',\n",
        " 'fiscal reporting',\n",
        " 'credit analysts:',\n",
        " 'credit risk assessment',\n",
        " 'financial statement analysis',\n",
        " 'credit scoring models',\n",
        " 'loan evaluation',\n",
        " 'regulatory compliance',\n",
        " 'financial and investment analysts:',\n",
        " 'investment analysis',\n",
        " 'financial modeling',\n",
        " 'portfolio management',\n",
        " 'market trends analysis',\n",
        " 'risk management',\n",
        " 'personal financial advisors:',\n",
        " 'financial planning',\n",
        " 'investment planning',\n",
        " 'retirement planning',\n",
        " 'estate planning',\n",
        " 'wealth management',\n",
        " 'insurance underwriters:',\n",
        " 'risk assessment',\n",
        " 'underwriting guidelines',\n",
        " 'insurance regulations',\n",
        " 'policy analysis',\n",
        " 'claims investigation',\n",
        " 'financial risk specialists:',\n",
        " 'risk management',\n",
        " 'derivatives trading',\n",
        " 'hedging strategies',\n",
        " 'financial modeling',\n",
        " 'compliance',\n",
        " 'financial examiners:',\n",
        " 'regulatory compliance',\n",
        " 'financial auditing',\n",
        " 'enforcement actions',\n",
        " 'fraud detection',\n",
        " 'reporting',\n",
        " 'credit counselors:',\n",
        " 'financial counseling',\n",
        " 'debt management',\n",
        " 'credit analysis',\n",
        " 'budgeting assistance',\n",
        " 'financial education',\n",
        " 'loan officers:',\n",
        " 'loan origination',\n",
        " 'credit analysis',\n",
        " 'risk assessment',\n",
        " 'customer relationship management',\n",
        " 'regulatory compliance',\n",
        " 'tax examiners and collectors',\n",
        " 'and revenue agents:',\n",
        " 'tax compliance',\n",
        " 'tax auditing',\n",
        " 'tax code knowledge',\n",
        " 'financial investigation',\n",
        " 'reporting',\n",
        " 'tax preparers:',\n",
        " 'tax preparation',\n",
        " 'irs regulations',\n",
        " 'tax planning',\n",
        " 'e-filing systems',\n",
        " 'client communication',\n",
        " 'financial specialists',\n",
        " 'all other:',\n",
        " 'financial consulting',\n",
        " 'investment advisory',\n",
        " 'due diligence',\n",
        " 'financial project management',\n",
        " 'regulatory compliance',\n",
        " 'financial quantitative analysts:',\n",
        " 'quantitative analysis',\n",
        " 'mathematical modeling',\n",
        " 'algorithm development',\n",
        " 'statistical analysis',\n",
        " 'programming (e.g.',\n",
        " 'python',\n",
        " 'r)',\n",
        " 'fraud examiners',\n",
        " 'investigators and analysts:',\n",
        " 'fraud detection',\n",
        " 'investigation techniques',\n",
        " 'forensic accounting',\n",
        " 'interview skills',\n",
        " 'report writing',\n",
        " 'computer systems analysts:',\n",
        " 'systems analysis',\n",
        " 'it project management',\n",
        " 'business process modeling',\n",
        " 'requirement gathering',\n",
        " 'software integration',\n",
        " 'health informatics specialists:',\n",
        " 'electronic health records (ehr)',\n",
        " 'health information exchange',\n",
        " 'healthcare it systems',\n",
        " 'data security in healthcare',\n",
        " 'health informatics standards',\n",
        " 'information security analysts:',\n",
        " 'cybersecurity',\n",
        " 'security risk assessment',\n",
        " 'incident response',\n",
        " 'security policy development',\n",
        " 'penetration testing',\n",
        " 'computer and information research scientists:',\n",
        " 'algorithm development',\n",
        " 'research methodologies',\n",
        " 'computational theory',\n",
        " 'data mining',\n",
        " 'artificial intelligence',\n",
        " 'computer network support specialists:',\n",
        " 'network troubleshooting',\n",
        " 'technical support',\n",
        " 'network security',\n",
        " 'hardware installation',\n",
        " 'network monitoring',\n",
        " 'computer user support specialists:',\n",
        " 'help desk support',\n",
        " 'customer service',\n",
        " 'troubleshooting',\n",
        " 'software installation',\n",
        " 'user training',\n",
        " 'computer network architects:',\n",
        " 'network design',\n",
        " 'network security',\n",
        " 'cloud computing architecture',\n",
        " 'protocols and standards',\n",
        " 'ip addressing',\n",
        " 'telecommunications engineering specialists:',\n",
        " 'telecommunications systems']) # Replace with your actual file path\n",
        "# Initialize a list to store matching skills\n",
        "matching_skills = []\n",
        "\n",
        "    # Check similarity for each skill in the resume\n",
        "for skill_resume in resume_skills:\n",
        "    if check_similarity(skill_resume, all_skills):\n",
        "        matching_skills.append(skill_resume)\n",
        "\n",
        "# Display the matching skills\n",
        "#print(\"Matching Skills:\", len(matching_skills), matching_skills\n",
        "final_skills = set(matching_skills)\n",
        "print(\"Matching skills : \",matching_skills)\n",
        "print(\"length is : \",len(matching_skills))\n",
        "print('\\n')\n",
        "print(\"Final skills : \",final_skills)\n",
        "print(\"length is : \",len(final_skills))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkYZGHocuLYo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import spacy\n",
        "\n",
        "# Load the large English model with word vectors\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "# Function to compute percentage match between skills in resume and job description using word embeddings\n",
        "def compute_percentage_match(resume_skills, job_description_skills, nlp):\n",
        "    # Initialize counters\n",
        "    matched_count = 0\n",
        "    total_skills_in_resume = len(resume_skills)\n",
        "\n",
        "    # Check similarity for each skill in resume with job description skills\n",
        "    for skill_resume in resume_skills:\n",
        "        for skill_job_desc in job_description_skills:\n",
        "            similarity = nlp(skill_resume).similarity(nlp(skill_job_desc))\n",
        "            # If similarity score is above threshold, consider it as a match\n",
        "            if similarity >= 0.55:  # Adjust threshold as needed\n",
        "                matched_count += 1\n",
        "                break  # Move to the next skill in resume\n",
        "\n",
        "    # Compute percentage match\n",
        "    percentage_match = (matched_count / total_skills_in_resume) * 100\n",
        "    return percentage_match\n",
        "\n",
        "# Extract skills from the job description\n",
        "job_description_skills = [ 'python', 'HTML', 'CSS', 'JavaScript', 'C','MySQL' , 'Scikit Learn', 'tensorflow', 'NLP', 'Cloud',\n",
        "'Front end Development',\n",
        "'Cybersecurity Management']\n",
        "# Extract skills from the resume (assuming matching_skills is already defined)\n",
        "\n",
        "# Compute percentage match between resume skills and job description skills using word embeddings\n",
        "percentage_match = compute_percentage_match(final_skills, job_description_skills, nlp)\n",
        "\n",
        "# Print the percentage match\n",
        "print(\"Percentage match between resume skills and job description skills:\", percentage_match)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
